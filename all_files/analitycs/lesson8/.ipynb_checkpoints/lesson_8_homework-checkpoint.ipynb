{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект урока 8. Работа с грязными данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения этого проекта скачайте Jupyter-ноутбук с описанием заданий отсюда. Загрузите его в JupyterHub. Откройте ноутбук и выполняйте задания в нём. Код вы будете писать в ноутбуке, а сдавать решения на проверку — в LMS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Объединение данных о покупках из папок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание**\n",
    "\n",
    "На этот раз данные имеют следующую структуру:\n",
    "\n",
    "* данные записываются для каждого пользователя, совершившего покупки, каждый день\n",
    "* для каждой даты есть своя папка, внутри неё — папки для каждого пользователя\n",
    "* внутри каждой папки пользователя есть файл `data.csv`, где и хранятся данные\n",
    "\n",
    "Схематично это выглядит так:\n",
    "\n",
    "```\n",
    "└── data\n",
    "   ├── 2020-12-30\n",
    "   │  ├── FirstName_LastName1\n",
    "   │  │   └── data.csv\n",
    "   │  ├── FirstName_LastName2\n",
    "   │  │   └── data.csv\n",
    "   │  └── FirstName_LastName3\n",
    "   │      └── data.csv\n",
    "   └── 2020-12-31\n",
    "      ├── FirstName_LastName1\n",
    "      │   └── data.csv\n",
    "      └── FirstName_LastName5\n",
    "          └── data.csv\n",
    "```\n",
    "\n",
    "Например, 30 декабря 2020 года три покупателя сделали покупки, 31 — два (папки 2020-12-30 и 2020-12-31 соответственно). \n",
    "\n",
    "Поскольку клиент `FirstName_LastName1` купил товары в оба дня, для него имеется папка в папке для каждой из дат. Для других клиентов — по одной.\n",
    "\n",
    "**Примечание**: данные в задании покрывают другой временной период, имена тоже другие. Подробности, примеры и возможные подсказки можно найти в текстах следующих шагов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задачи**\n",
    "1. Соберите все данные из папки `data` в один датафрэйм, имеющий следующие столбцы: колонки из самих файлов (`product_id`, `quantity`), а также имя пользователя (`name`), и дата этих покупок (`date`), соответствующие названию папок, где лежит файл.\n",
    "2. Выясните, какой пользователь купил больше всего товаров. Если их несколько, то перечислите имена через запятую с пробелом и в алфавитном порядке.\n",
    "3. Найдите топ-10 товаров по числу проданных единиц за всё время и постройте барплот. Сколько было продано единиц товара с `product_id==56`?\n",
    "4. Визуализируйте продажи по дням.\n",
    "5. Сколько пользователей приобрели какой-либо товар повторно (более 1 раза)? Повтором будем считать покупку товара с одинаковым `product_id`, совершенную в разные дни. \n",
    "\n",
    "Найти данные можно либо на JupyterHub, либо скачать архив [отсюда](https://yadi.sk/d/fkzS9UYSr59EQQ).\n",
    "\n",
    "\n",
    "Вы можете решать задания тем способом, который считаете наиболее удобным или оптимальным. А для того, чтобы лучше понять задание, следуйте по шагам выполнения. Бывает, что их можно выполнить в одну строчку, применяя методы друг за другом. А если выполняете шаги отдельно, не забудьте сохранить результат в переменную, чтобы в следующем шаге работать именно с ней.\n",
    "\n",
    "В ноутбуке место для вашего решения обозначено комментарием `# Ваш код здесь`, но вы можете писать код там, где вам удобно, добавлять или удалять ячейки с кодом или текстом по вашему усмотрению.\n",
    "\n",
    "Кроме того можно посмотреть подсказки, кликнув на строчку `► Нажмите сюда, чтобы увидеть подсказку`. Также не забывайте о наличии конспектов и возможности задать вопрос в `Discord`, ссылка на нужный тред есть на странице каждого шага в LMS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберите все данные из папки `data` в один датафрэйм, имеющий следующие столбцы: колонки из самих файлов (`product_id`, `quantity`), а также имя пользователя (`name`), дата этих покупок (`date`), соответствующие названию папок, где лежит файл.\n",
    "\n",
    "Пример итоговой таблицы:\n",
    "\n",
    "|#|product_id|quantity|name|date|                                                                                     \n",
    "|:-|:----|:-----|:--|:-----|                                              \n",
    "|0|56|2|Anatoly_Karpov|2020-12-30|\n",
    "|1|7|2|Anatoly_Karpov|2020-12-30|\n",
    "|2|9|3|Anatoly_Karpov|2020-12-30|\n",
    "\n",
    "Для объединения датафреймов, читаемых из файлов, можно использовать метод `pd.concat()`. Например:\n",
    "\n",
    "1. Имеются следующие данные:\n",
    "\n",
    "```python\n",
    "> df_1\n",
    "```\n",
    "\n",
    "|#|product_id|quantity|name|date|                                                                                     \n",
    "|:-|:----|:-----|:--|:-----|                                              \n",
    "|0|56|2|Anatoly_Karpov|2020-12-30|\n",
    "|1|7|2|Anatoly_Karpov|2020-12-30|\n",
    "|2|9|3|Anatoly_Karpov|2020-12-30|\n",
    "\n",
    "```python\n",
    "> df_2\n",
    "```\n",
    "\n",
    "|#|product_id|quantity|name|date|                                                                                     \n",
    "|:-|:----|:-----|:--|:-----|                                              \n",
    "|0|4|2|Кatya_Skriptsova|2020-12-30|\n",
    "|1|71|1|Кatya_Skriptsova|2020-12-31|\n",
    "\n",
    "2. Соединяем, передав `pd.concat` на вход список датафреймов, которые нужно объединить. Обратите внимание: индексы повторяются, поэтому после соединения всех данных нужно их сбросить.\n",
    "\n",
    "```python\n",
    "> df = pd.concat([df_1, df_2])\n",
    "> df\n",
    "```\n",
    "|#|product_id|quantity|name|date|                                                                                     \n",
    "|:-|:----|:-----|:--|:-----|                                              \n",
    "|0|56|2|Anatoly_Karpov|2020-12-30|\n",
    "|1|7|2|Anatoly_Karpov|2020-12-30|\n",
    "|2|9|3|Anatoly_Karpov|2020-12-30|\n",
    "|0|4|2|Кatya_Skriptsova|2020-12-30|\n",
    "|1|71|1|Кatya_Skriptsova|2020-12-31|\n",
    "\n",
    "\n",
    "\n",
    "**Рекомендуем решать данное задание через `os.walk()`.**\n",
    "\n",
    "**В качестве ответа укажите сумму по колонке `quantity`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаги выполнения:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Для начала составим путь `way` до папки `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "\n",
    "Сначала необходимо прописать путь к папке `data`, предварительно сохранив этот путь в переменную (к примеру, `way`).\n",
    "      \n",
    "А как построить путь до папки `data`?\n",
    "      \n",
    "* Вы можете использовать абсолютный путь к файлу, пропишите `~/`, нажмите `tab` и стройте путь до желаемого файла/папки:\n",
    "      \n",
    "```python\n",
    "'...shared/homeworks/python_ds_miniprojects/7/data'\n",
    "```\n",
    "      \n",
    "Например, путь до папки `data` у пользователя `аn-кarpov`, будет выглядеть следующим образом:\n",
    "      \n",
    "```python\n",
    "'/mnt/HC_Volume_18315164/home-jupyter/jupyter-аn-кarpov/shared/homeworks/python_ds_miniprojects/7/data/'\n",
    "```\n",
    "Чтобы построить свой путь, вместо `аn-кarpov` необходимо указать ваш логин, используемый в LMS. \n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Пройдемся по результату построения пути до папки `data` методом `os.walk(way)` простым циклом и распечатаем каждый элемент, посмотрим, что получилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "\n",
    "Метод `os.walk` принимает путь к папке, проходится по всем подпапкам в ней и доходит до конечных файлов в них, выдавая на каждой итерации:\n",
    "* путь к папке, которую мы сейчас смотрим: `path`\n",
    "* список подпапок в ней: `dirs`\n",
    "* список файлов в ней: `files`\n",
    "      \n",
    "\n",
    "```python\n",
    "for path, dirs, files in os.walk(way):\n",
    "    print(path, dirs, files)  \n",
    "```\n",
    "      \n",
    "Результатом выполнения такого цикла будет генератор, который генерирует кортежи для каждой директории в дереве каталогов. Каждый кортеж содержит три элемента: путь к папке, список подпапок в текущей папке и список имен файлов в них, не являющихся папками.\n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Далее попробуем с помощью циклов и `os.path.join(path, file)` построить пути до каждого файла в подпапке `2020-12-05` и распечатать их."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "\n",
    "Теперь в цикл `for` в метод `os.walk()` передайте путь к подпапке `2020-12-05`: \n",
    "\n",
    "`'...shared/homeworks/python_ds_miniprojects/7/data/2020-12-05'`\n",
    "      \n",
    "Далее используйте вложенный цикл `for` для обхода всех файлов (`files`) в текущем пути.\n",
    "      \n",
    "И после с помощью метода `os.path.join(path, file)` постройте полный путь к текущему файлу, объединяя текущий путь `path` и имя файла `file`:\n",
    "      \n",
    "```python\n",
    "      \n",
    "for path, dirs, files in os.walk(f'/mnt/HC_Volume_18315164/home-jupyter/jupyter-{student_login}/shared/homeworks/python_ds_miniprojects/7/data/2020-12-05'):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(path, file)\n",
    "        print(file_path)\n",
    "```\n",
    "   \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Теперь можно использовать полученные знания, чтобы с помощью метода `os.walk()` построить пути до всех файлов с расширение `.csv`, находящихся в подпапках, в папке `data`, и сохранить эти данные в список. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "\n",
    "Создайте пустой список, например, `file_paths`, куда будете добавлять получившиеся пути к файлам.\n",
    "      \n",
    "Теперь используйте метод `os.walk`, который принимает путь к папке и проходится по всем подпапкам в ней, выдавая на каждой итерации:\n",
    "* путь к папке, которую мы сейчас смотрим: `path`\n",
    "* список подпапок в ней: `dirs`\n",
    "* список файлов в ней: `files`\n",
    "      \n",
    "Далее используйте вложенный цикл `for` для обхода всех файлов (`files`) в текущем пути.\n",
    "      \n",
    "С помощью условного оператора `if` проверьте имеют ли файлы в подпапках расширение '.csv'. \n",
    "      \n",
    "Если да, то с помощью метода `os.path.join(path, file)` постройте полный путь к текущему файлу, объединяя текущий путь `path` и имя файла `file`.\n",
    "      \n",
    "Не забудьте добавлять получившиеся пути в созданный ранее список.\n",
    "      \n",
    "      \n",
    "```python\n",
    "# Создаём пустой список file_paths, в который будут добавляться пути к файлам.\n",
    "file_paths = []\n",
    "# Запускаем цикл for cовместно с методом os.walk() по папке data\n",
    "# В переменной path находится текущий путь (папка data), dirs — список подпапок в текущей папке, files — список файлов в них\n",
    "for path, dirs, files in os.walk(way):\n",
    "\t# Вложенный цикл для перебора файлов в текущей папке\n",
    "    for file in files:\n",
    "\t\t# Проверка формата файла — файл должен заканчиваться на '.csv'\n",
    "        if file.endswith('.csv'):\n",
    "\t\t    # Построение полного пути к файлу с помощью os.path.join(), объединяя текущий путь path и имя файла file\n",
    "            file_path = os.path.join(path, file)\n",
    "            # Добавляем получившийся путь в список\n",
    "            file_paths.append(file_path)      \n",
    "```\n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пути к файлам мы получили, что дальше?**\n",
    "\n",
    "5. Теперь необходимо считать данные файлы, собрав их в один датафрэйм, имеющий следующие столбцы: колонки из самих файлов (`product_id`, `quantity`), а также: имя пользователя(`name`) и дату этих покупок (`date`), которые можно получить из соответствующих названий папок, где лежат файлы.\n",
    "\n",
    "   Как мы помним, пути к каждому файлу уже построены, а значит можно прочитать все файлы. \n",
    "\n",
    "   Поскольку название путей — это строки, то мы можем, использовав строковые методы, достать из путей нужную нам часть, а именно: информацию об имени пользователя и о дате покупки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "\n",
    "А с чего тут начать?\n",
    "      \n",
    "Создаем пустую таблицу данных, например, `df`, которую мы будем заполнять данными:\n",
    "      \n",
    "```python\n",
    "df = pd.DataFrame() \n",
    "```\n",
    "\n",
    "Запускаем цикл для каждого пути к файлу `i` из списка путей — `file_paths`, и для каждого `i` выполняем следующие действия:\n",
    "      \n",
    "* Считываем данные с помощью `pd.read_csv(i)` и сохраняем их в переменную, возьмем, например, `data`, таким образом, у нас в переменной `data` на каждой итерации будут оказываться мини-таблицы соответствующие каждому пути\n",
    "* Добавляем новые столбцы и значения в таблицы:\n",
    "\n",
    "```python\n",
    "data['name'] = значения\n",
    "data['date'] = значения ```\n",
    "      \n",
    "Как уже упоминалось, каждый путь представляет собой строку (расположение данных в путях одинаковое), элементы которой разделены `/`, поэтому мы можем использовать строковый метод `split()` с разделителем `/`, разделить по нему путь к файлу и с помощью индексов достать нужные части.\n",
    "      \n",
    "Например:\n",
    "      \n",
    "```python\n",
    "str_way = 'shared/homeworks/python_ds_miniprojects/7/data/2020-12-05/Petr_Ivanov/data.csv'\n",
    "name = str_way.split('/')[-2]\n",
    "      \n",
    "#Вывод\n",
    "'Petr_Ivanov'\n",
    "\n",
    "```\n",
    "Объедините с помощью метода `pd.concat()` созданный перед циклом пустой датафрейм `df` и считанный в цикле `data`.\n",
    "\n",
    "Таким образом каждый мини-датафрейм будет считываться на каждой итерации, в него будут добавляться колонки с датой и именем, а далее он будет добавлен в общий датафрейм.\n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Осталось сбросить индексы и посчитать сумму по колонке `quantity`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "\n",
    "Чтобы сбросить индекс датафрэйма на стандартные числа от 0 до числа строк -1, используйте метод `reset_index`. \n",
    "А для того, чтобы старый индекс не стал колонкой, а просто ушёл, укажите параметр `drop=True`. \n",
    "\n",
    "Например,\n",
    "\n",
    "```python\n",
    "df.reset_index(drop=True)\n",
    "```\n",
    "вернёт датафрэйм, где вместо оригинального индекса будет стандартный.\n",
    "\n",
    "Для вычисления суммы значений `quantity` используйте метод `sum()` к этой колонке. \n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выясните, какой пользователь купил больше всего товаров. Если их несколько, то перечислите имена через запятую с пробелом и в алфавитном порядке. Например:\n",
    "\n",
    "```python\n",
    "Anatoly_Karpov, Nekto_Ktotovich, Lena_Uhanova, Ignat, Sasha_Tokarev\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "\n",
    "А как быть тут?\n",
    "    \n",
    "Сгруппируйте данные по пользователям (`name`) и посчитайте для каждого пользователя сумму по числу заказов (`quantity`). Потом отберите только имена тех, у кого максимальное число покупок.\n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите топ-10 товаров по числу проданных единиц за всё время и постройте барплот (столбчатую диаграмму, `sns.barplot`), где:\n",
    "\n",
    "* по оси x — идентификаторы товаров (`product_id`) \n",
    "* по оси y — суммарное число их покупок (сколько товаров с таким `product_id` было продано)\n",
    "\n",
    "Для практики попробуйте изменить параметры графика, например: цвет (`color`), сортировку значений по оси х (`order`). \n",
    "\n",
    "В качестве ответа укажите, сколько было продано единиц товара с `product_id` равным `56`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "\n",
    "Как делать это задание?\n",
    "\n",
    "Сгруппируйте данные по товарам (`product_id`) и посчитайте для каждого товара сумму по числу заказов (`quantity`). Для визуализации используйте `sns.barplot`.\n",
    "      \n",
    "Для построения нужного графика импортируйте `seaborn` и `matplotlib.pyplot`, вызовите `sns.barplot`, указав там нужные `x` и `y`. \n",
    "      \n",
    "Например,\n",
    "\n",
    "```python\n",
    "sns.barplot(x=df.col_x, y=df.col_y)\n",
    "```\n",
    "построит график с соответствующими координатами `x` и `y` из колонок `col_x` и `col_y` для столбиков.\n",
    "\n",
    "Альтернативно можно указать в `x` и `y` только названия нужных колонок в кавычках, а также передать в `data` переменную с датафрэймом:\n",
    "\n",
    "```python\n",
    "sns.barplot(x='col_x', y='col_y', data=df)\n",
    "```  \n",
    "Чтобы указать параметры графика: цвет (`color`), сортировку значений по оси `х` (`order`), введите их в функцию `sns.barplot`.\n",
    "      \n",
    "Сортировку значений можно задать следующим образом:\n",
    "      \n",
    "```python\n",
    "sns.barplot(x='col_x', y='col_y', data=df, order=df.sort_values('col_y').col_x, ax=ax)\n",
    "```\n",
    "      \n",
    "Подробнее можно посмотреть в [документации](https://seaborn.pydata.org/generated/seaborn.barplot.html).\n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на продажи по дням! Для визуализации снова используйте барплот, только теперь по оси `x` будут дни, по которым у нас есть данные (`date`). \n",
    "\n",
    "Далее выберите верные утверждения:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Меньше всего товаров было приобретено 6 декабря\n",
    "* 5 декабря было куплено почти в три раза меньше товаров, чем в предыдущий день\n",
    "* 8 и 9 декабря было продано примерно одинаковое число товаров\n",
    "* Максимальное число товаров было продано 4 декабря\n",
    "* Меньше всего продуктов было приобретено 4 декабря\n",
    "* 4 декабря было куплено почти в два раза больше товаров, чем в предыдущий день\n",
    "* 5 декабря было куплено почти в два раза больше товаров, чем в предыдущий день\n",
    "* 7 декабря было куплено почти в два раза больше товаров, чем в предыдущий день"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "      \n",
    "Сгруппируйте данные по датам (`date`) и посчитайте для каждого дня сумму по числу заказов (`quantity`). Для визуализации используйте `sns.barplot`.\n",
    "      \n",
    "С помощью графика ответьте на вопросы по заданию.\n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько пользователей приобрели какой-либо товар повторно (более 1 раза)? Повтором будем считать покупку товара с одинаковым `product_id`, совершенную в разные дни. \n",
    "\n",
    "Например, пользователь `Sasha Tsarev` дважды приобрел товар `6`. Поскольку покупка была совершена в один и тот же день, повторной в данном случае она считаться не будет. \n",
    "\n",
    "`Katya Skriptsova` также сделала две покупки товара `7`, но в разные дни, поэтому этот случай засчитывается.\n",
    "\n",
    "|product_id|quantity|name|date|                                                                                     \n",
    "|:----|:-----|:--|:-----|                                              \n",
    "|25|2|Кatya_Skriptsova|2020-12-05|\n",
    "|54|1|Olya_Silyutina|2020-12-05|\n",
    "|7|4|Кatya_Skriptsova|2020-12-05|\n",
    "|6|4|Sasha_Tsarev|2020-12-06|\n",
    "|6|1|Sasha_Tsarev|2020-12-06|\n",
    "|7|5|Кatya_Skriptsova|2020-12-06|\n",
    "\n",
    "Может пригодиться: `.drop_duplicates()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "\n",
    "Один из вариантов решения — удалить дубликаты по имени, продукту и дате. Это оставит только по одной строке на каждую покупку продукта в день. Затем нужно сгруппировать по колонкам `name` и `product_id` и посчитать число дней покупок каждого продукта для каждого человека (то есть число строк в группе). \n",
    "      \n",
    "После этого отобрать строки со значением больше `1`, то есть только строки пользователей, купивших что-то в разные дни.\n",
    "\n",
    "Для удаления повторяющихся строк используется метод `drop_duplicates()`. Под повторяющимися имеется в виду, что значения в этих строках во всех их колонках одинаковые:\n",
    "    \n",
    "```python\n",
    "df.drop_duplicates()\n",
    "```\n",
    "Такой код вернёт датафрэйм, где не будет повторяющихся строк, но чтобы смотреть на повторность не по всем столбцам, а только по части, необходимо воспользоваться параметром `subset`.\n",
    "    \n",
    "```python\n",
    "df.drop_duplicates(subset='my_unique_column')\n",
    "```\n",
    "Так мы получим датафрэйм, где не будет строк с одинаковым значением в колонке `my_unique_column`      \n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Обработка данных телемаркетинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном проекте путём объединения файлов о продажах с логами по подключениям в системе, вы сможете проверить корректность подключений определенных пользователей. \n",
    "\n",
    "В папке `subsid` (`'...shared/homeworks/python_ds_miniprojects/7_subsid/subsid'`) находятся файлы (`tm_sales_1.csv`, `tm_sales_2.csv`, `tm_sales_3.csv`) с продажами продуктов через телемаркетинг, каждый из которых содержит колонки (поля): `FILIAL_ID`, `SUBS_ID`, `PROD_ID`, `ACT_DTTM`. \n",
    "\n",
    "А также файл `prod_activations_logs.csv` с данными о подключениях в системе, который содержит колонки: `SUBS_ID`, `PROD_ID`, `START_DTTM`, `END_DTTM`.\n",
    "\n",
    "Суть задачи в том, чтобы проверить подключения продуктов определенным пользователям, соединив файлы о продажах с логами по подключениям в системе.\n",
    "\n",
    "Особенности данных:\n",
    "\n",
    "* если в файле с продажами встречается строка без указанного `SUBS_ID`, она пропускается\n",
    "* сотрудники телемаркетинга не всегда указывают полный `id`, если `'id'` нет в начале `SUBS_ID`, то нужно его добавить\n",
    "* поля в файлах могут быть расположены абсолютно случайным образом, но названия полей статичны\n",
    "* колонки с датами необходимо перевести в формат `datetime`(временной тип)\n",
    "* продажа не засчитывается, если отключение (`END_DTTM`) произошло меньше чем через 5 минут после подключения (`START_DTTM`)\n",
    "\n",
    "\n",
    "Сохраните результат в `csv` файл с разделителем `;`, содержащий корректные подключения.\n",
    "\n",
    "**Примечание:** обратите внимание на то, как `pandas` переводит дату из строки, возможно вам понадобится параметр `format`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки результатов введите `SUBS_ID` из полученного датасета в порядке возрастания, через запятую с пробелом. \n",
    "\n",
    "Например:\n",
    "\n",
    "```python\n",
    "id1, id2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаги выполнения:**\n",
    "\n",
    "1. Сначала прочитайте `csv` файлы удобным для вас способом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "      \n",
    "Вы можете использовать абсолютные пути и считать файлы из папки `'~/...shared/homeworks/python_ds_miniprojects/7_subsid/subsid'`\n",
    "      \n",
    "Либо скачать файлы из папки `shared`, поместить их в свой Jupyter-ноутбук в папку, где расположен данный ноутбук и считать оттуда.\n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Теперь объединим датафреймы с продажами продуктов через телемаркетинг `tm_sales_1`, `tm_sales_2`, `tm_sales_3` в единую таблицу, а также избавимся от строк, где пропущено значение по колонке `SUBS_ID`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "      \n",
    "Объединить таблицы можно с помощью метода `pd.concat()`:\n",
    "      \n",
    "```python\n",
    "full_df = pd.concat([df1, df2])\n",
    "```\n",
    "Для того чтобы избавиться от пропущенных значений в строках по какому-то из столбцов(колонок), используйте метод `dropna()` с параметром `subset`, в который можно передать в виде списка набор колонок, где необходимо избавиться от наличия пропущенных значений.\n",
    "    \n",
    "Например, следующий код  вернёт датафрэйм без строк, где в колонке `col1` были пропущенные значения:\n",
    "    \n",
    "```python\n",
    "df.dropna(subset=['col1'])\n",
    "```\n",
    "        \n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. В задании указано, что сотрудники телемаркетинга не всегда указывают полный `id`, поэтому далее нам необходимо в случае отсутствия  `'id'` в начале значений по колонке `SUBS_ID` добавить его. \n",
    "\n",
    "   Это можно сделать разными способами, в подсказках будет предложен один из вариантов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "      \n",
    "Вы можете сделать обычную функцию(`def`), работающую на одном значении `x` и прибавляющую к нему `id` при необходимости, передав её в `apply`, либо сделать сразу `лямбда-функцию` внутри метода `apply`.\n",
    "      \n",
    "Обратите внимание, что применять функцию необходимо ни ко всему датафрейму, а к колонке, значения в которой необходимо преобразовать:\n",
    "      \n",
    "```python\n",
    "df['сol_1'] = tm_sales['сol_1'].apply(function)          \n",
    "```\n",
    "      \n",
    "А как добавить `'id'` в начало `SUBS_ID`?\n",
    "    \n",
    "Здесь на помощь может прийти конкатенация строк (`'id' + необходимое_значение`). \n",
    "      \n",
    "Можно реализовать функцию, которая будет принимать значение `x`, проверять на наличие `'id'` в начале строки и взависимости от этого либо добавлять `'id'` в начало строки, либо нет.\n",
    "   \n",
    "Проверить наличие какого-то значения в начале строки `x` поможет метод `x.startswith('id')`\n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Далее объедините таблицы с продажами с данными о подключениях в системе (таблица `prod_activations_logs.csv`) по колонкам `SUBS_ID` и `PROD_ID`.\n",
    "\n",
    "    Также переведите колонки с датами к необходимому типу данных. Обратите внимание на формат считываемых данных в колонках, содержащих сведения о дате и времени, всё ли верно считывается? \n",
    "\n",
    "    Может пригодиться использование параметра `format` для приведения данных к верному формату."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "      \n",
    "Для объединения таблиц с продажами с данными о подключениях в системе (таблица `prod_activations_logs.csv`)  используйте `merge` c  `inner join` по колонкам `SUBS_ID` и `PROD_ID`.\n",
    "      \n",
    "Чтобы перевести данные во время, используйте функцию `pd.to_datetime`. Она принимает колонку, которую нужно перевести во время, и возвращает её во временном типе.\n",
    "\n",
    "Например,\n",
    "\n",
    "```python\n",
    "pd.to_datetime(df['time_column'])\n",
    "```\n",
    "вернёт колонку `time_column` во временном типе.\n",
    "      \n",
    "А где ошибка-то?\n",
    "      \n",
    "Давайте посмотрим на примере значений колонки 'END_DTTM'. Выведите значения это колонки до преобразования во временной тип:\n",
    "      \n",
    "```python\n",
    "sales_logs['END_DTTM']\n",
    "      \n",
    "# Вывод\n",
    "0    01-12-2020 00:00\n",
    "1    19-03-2020 13:03\n",
    "2    25-03-2020 11:00\n",
    "3    01-12-2020 00:00\n",
    "4    15-03-2020 23:42\n",
    "Name: END_DTTM, dtype: object\n",
    "```\n",
    "А теперь с использованием `to_datetime()` без форматирования:\n",
    "      \n",
    "```python\n",
    "pd.to_datetime(sales_logs['END_DTTM'])\n",
    "      \n",
    "# Вывод\n",
    "0   2020-01-12 00:00:00\n",
    "1   2020-03-19 13:03:00\n",
    "2   2020-03-25 11:00:00\n",
    "3   2020-01-12 00:00:00\n",
    "4   2020-03-15 23:42:00\n",
    "Name: END_DTTM, dtype: datetime64[ns]\n",
    "```\n",
    "Как вы можете видеть, дату '01-12-2020 00:00' Python считал неверно, перепутав день с месяцем (01 и 12).\n",
    "      \n",
    "Хорошо, а как изменить формат считываемых данных?\n",
    "    \n",
    "Для этого используется параметр `format` в функции `pd.to_datetime`.\n",
    "      \n",
    "Например,\n",
    "\n",
    "```python\n",
    "pd.to_datetime(df['time_column'], format='%d-%m-%Y %H:%M')\n",
    "```\n",
    "Распарсит время, которое находится в данных в формате `день-месяц-год час:минута`. То есть строка внутри `format` содержит шаблон того, что находится в данных. Процент перед `d`, `m`, `Y`, `H` и `M` говорит питону, что это специальный символ (в нашем случае день, месяц, год, час, минута). Другие спецификаторы можно посмотреть [здесь](https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior).\n",
    "\n",
    "**Обратите внимание!** `format` задаёт только то, как считываются данные. Отображаться в самом датафрейме дата всегда будет в формате *год-месяц-день*. Поэтому не пугайтесь того, что вы написали ему *день-месяц-год*, а пишет он в другом порядке — это нормально. \n",
    "      \n",
    "**Почему пандас неправильно читает дату?**\n",
    "Судя по всему, он сначала пытается считать по американскому формату, у него получается, и из-за этого возникает ошибка.\n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Осталось найти разницу между временем подключения (`START_DTTM`) и отключения (`END_DTTM`), а затем отобрать только те значения, где разница составляет больше 5 минут, поскольку по условию задания продажа не засчитывается, если отключение (`END_DTTM`) произошло меньше чем через 5 минут после подключения (`START_DTTM`).\n",
    "\n",
    "    Сохраните результат в `csv` файл с разделителем `;`, содержащий корректные подключения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "      \n",
    "Для того, чтобы узнать разницу во времени между подключением (`START_DTTM`) и отключением (`END_DTTM`), необходимо просто произвести вычитание: из времени отключения (`END_DTTM`) отнять время подключения (`START_DTTM`).\n",
    "      \n",
    "Данные по разнице во времени передайте в колонку, например, `diff_DTTM`:\n",
    "      \n",
    "```python\n",
    "df['diff_DTTM'] = df['col1'] - df['col2']     \n",
    "```\n",
    "    \n",
    "Чтобы отфильтровать датафрейм, оставляя только те строки, где разница между значениями в столбце `diff_DTTM` больше 5 минут,\n",
    "можно создать объект типа Timedelta, представляющий 5 минут — pd.Timedelta(5, 'm'), и сравнить значения в столбце с ним:\n",
    "      \n",
    "```python\n",
    "df['diff_DTTM'] > pd.Timedelta(5, 'm')    \n",
    "```\n",
    "Результатом выполнения этой строки кода будет колонка из `True` и `False`, где `True` стоит напротив элементов, которые были больше 5 минут, и `False` в противном случае.\n",
    "      \n",
    "      \n",
    "Как записать датафрэйм в файл?\n",
    "    \n",
    "Сделайте это с помощью метода `to_csv`, который принимает строку — путь к файлу, куда вы запишете файл, не забудьте про разделитель `sep=';'`. \n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Геном мухи и работа с нестандартным форматом данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном проекте вы поработаете с довольно нетипичными для аналитика данными: `gff файлом`, который описывает геном мухи (описание формата можно найти [здесь](http://gmod.org/wiki/GFF3)). \n",
    "\n",
    "При его выполнении вам может понадобиться часть конспекта про работу с регулярными выражениями и со строковыми данными.\n",
    "\n",
    "**Задачи**:\n",
    "\n",
    "* выделите из колонки `attributes` значение атрибута `Parent`, то есть если там записано `Parent=x,`, `something;Parent=x` или `Parent=x;something`, то нам нужен только `x`\n",
    "* выясните, какое из этих значений является самым частым\n",
    "* постройте распределение встречаемости значений в столбце `type`\n",
    "\n",
    "Данные можно достать с JupyterHub из папке `7_gff` (`'...shared/homeworks/python_ds_miniprojects/7_gff'`) , либо [отсюда](https://stepik.org/media/attachments/course/72204/gff.tsv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое значение атрибута `Parent` самое частое?\n",
    "\n",
    "Вам необходимо извлечь из колонки `attributes` значение атрибута `Parent` для каждой строки и найти самый частый."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "\n",
    "Как это сделать?   \n",
    "      \n",
    "Чтобы извлечь из колонки `attributes` значение атрибута `Parent`, можно воспользоваться регулярными выражениями. \n",
    "      \n",
    "Если посмотреть на второе значение из колонки `attributes`, то мы увидим следующее:\n",
    "      \n",
    "```python\n",
    "df.attributes.iloc[1]\n",
    "      \n",
    "# Вывод\n",
    "'Name=CDS:NC_000083.5:LOC100040603;Parent=XM_001475631.1,'\n",
    "```\n",
    "Как видно, чтобы получить необходимое значение, необходимо отобрать всё после `Parent=`, за исключением запятой в конце. При этом обратите внимание, что после `XM_001475631` стоит точка `.`, после которой следует одна цифра `1`. Такое строение атрибута `Parent` характерно для всех значений в колонке `attributes`.\n",
    "      \n",
    "Как написать регулярное выражение, подходящее к условию задания:\n",
    "      \n",
    "* cначала укажите подстроку, выражение после которого мы ищем — `Parent=`\n",
    "      \n",
    "* далее создайте именованную группу, которая позволяет обращаться к найденной подстроке по имени parent — `(?P<parent>...)`\n",
    "      \n",
    "* внутри именной группы (вместо троеточий) в квадратных скобках вставьте необходимые метасимволы: любая буква, цифра или _ (words) — `\\w`; символ соответствуещей точке — `\\.`\n",
    "      \n",
    "* за квадратными скобками также вставьте знак `+`, который указывает, что предыдущий шаблон должен встречаться один или более раз\n",
    "\n",
    "Таким образом, это регулярное выражение будет искать подстроку, начинающуюся с `Parent=`, за которой следует любая комбинация букв, цифр, символов подчеркивания и точек.\n",
    "      \n",
    "```python\n",
    "import re\n",
    "\n",
    "# Создадим строку, из которой нам необходимо достать значение после `Value=`\n",
    "test = \"Parameters: Name=John, Age=30, Value=42.5;HO-34, Status=Active\"\n",
    "\n",
    "# Создаём нужный паттерн\n",
    "pattern = re.compile('Value=(?P<value>[\\d\\.]+)')\n",
    "# Ищем его в тексте\n",
    "pattern.findall(test)\n",
    "      \n",
    "# Вывод\n",
    "['42.5']\n",
    "      \n",
    "```\n",
    "      \n",
    "Для извлечения информации из колонки датафрейма с помощью регулярного выражения `pattern` используйте метод `extract` на столбце датафрейма:\n",
    "      \n",
    "```python\n",
    "gff.attributes.str.extract(pattern)      \n",
    "```\n",
    "      \n",
    "А можно решить это задание другим способом?\n",
    "      \n",
    "На самом деле решений может быть множество. Можно сделать это с помощью использования различных строковых методов, функций, циклов и т.д.\n",
    "      \n",
    "Например, для отбора колонок с необходимым значением существуют разные методы. Как один из вариантов вы можете использовать строковый метод `.str.contains(\"<паттерн, нужно найти>\")`, который можно применить к колонке, где надо найти паттерн.\n",
    "После того, как вы отберете строки с `Parent`, можно разбить их по знаку `=` и взять только нужную часть, также не забудьте избавиться от лишних значений после `:`. \n",
    "\n",
    "Также можно воспользоваться строковым методом `split` с разными разделителями и индексацией. Как мы видим, чтобы получить значение после `Parent=`, нам нужно разделить значения в каждой строке по `;` и взять часть с `Parent`, далее разделить и эту часть по `=` и взять значение, которое шло после равно, а далее снова произвести разделение по `:` и взять первый элемент(с индексом 0). \n",
    "      \n",
    "У меня осталась запятая в конце значений, это нормально?    \n",
    "Нет, используйте `strip`, чтобы убрать её. Метод `strip` убирает с краёв строки переданные в него символы. \n",
    "      \n",
    "Например,\n",
    "    \n",
    "```python\n",
    "df.col1.str.strip('.')\n",
    "```\n",
    "уберёт спереди и сзади значений колонки `col1` точки.\n",
    "      \n",
    "А как реализовать такой подход не только к одной строке, а к значениям всей колонки?\n",
    "      \n",
    "Как вариант напишите функцию, в которой для одного списка будет искаться пара `Parent`, и примените её ко всей колонке с помощью функции `apply`.\n",
    "     \n",
    "Как искать пару в списке?\n",
    "    \n",
    "Для этого можно использовать оператор `in`:\n",
    "    \n",
    "Например,\n",
    "    \n",
    "```python\n",
    "'abc' in 'abc is a start of the alphabet'\n",
    "```\n",
    "вернёт `True`, а\n",
    "    \n",
    "```python\n",
    "'!!!' in 'abc is a start of the alphabet'\n",
    "```\n",
    "вернёт `False`.\n",
    "    \n",
    "Можно использовать это в условии в цикле по списку и отбирать только элементы с `Parent`.\n",
    "      \n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте распределение встречаемости значений в колонке `type`.\n",
    "\n",
    "Какое самое частое значение в колонке `type`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* exon\n",
    "* CDS\n",
    "* five_prime_UTR\n",
    "* mRNA\n",
    "* protein\n",
    "* three_prime_UTR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>&#9658; Нажмите сюда, чтобы увидеть подсказку</summary>\n",
    "  <p>\n",
    "      \n",
    "Чтобы посмотреть на распределение встречаемости значений в колонке `type`, можно построить график `countplot`, который позволяет отобразить количество наблюдений для каждого уникального значения категориальной переменной.\n",
    "      \n",
    "Для использования графика `countplot` не нужно заранее проводить агрегацию данных, функция сама посчитает частоту встречаемости каждой переменной.\n",
    "      \n",
    "Синтаксис функции `countplot` в библиотеке `seaborn` выглядит следующим образом:\n",
    " \n",
    "```python\n",
    "sns.countplot(x='column_name', data=data)\n",
    "```\n",
    "Где `x` — это название столбца (переменной), значения которого будут отображаться на оси `X` графика.\n",
    "      \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
